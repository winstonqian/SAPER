\section{Discussion}

\subsection{Why SAPER Works}

SAPER's task-specific gains reflect the structure-function paradigm in protein biology. Domain/Motif identification (+114\% Meta-BLEU-2) benefits most because protein domains are defined by 3D architecture—spatial arrangements of secondary structure elements into folds like immunoglobulin domains or Rossmann folds. These structural motifs arise through convergent evolution in proteins with <20\% sequence identity, making them invisible to sequence-only retrieval. ProstT5's 3Di structural alphabet encodes local geometric environments, enabling recognition of distant structural homologs that ESM-2 misses.

Catalytic Activity (+53.2\%) similarly depends on active site geometry. Serine proteases across diverse families share Ser-His-Asp catalytic triads recognizable only through structural alignment, not sequence comparison. ProstT5 identifies these geometric similarities despite sequence divergence.

Conversely, Protein Function (+19.5\%) shows modest gains because annotations emphasize biological processes and pathway membership—features tied to evolutionary history. Sequence-based ESM-2 captures these relationships effectively, making structural emphasis ($\alpha=0.7$) less beneficial. This explains why RRF's equal weighting (+5.1\%) outperforms Weighted Similarity ($-$0.4\%) for this task.

Weighted Similarity's advantage over RRF stems from leveraging score magnitudes and emphasizing structure (70\% weight). In the sequence identity ``twilight zone'' (20--30\%) where homology detection fails, structural conservation extends further. By trusting ProstT5 matches more, Weighted Similarity improves retrieval for OOD proteins in this critical regime.

Enhanced prompts boost performance through: (1) task-specific instructions activating LLM domain knowledge, (2) confidence signals enabling weighted integration of evidence, (3) structured formatting reducing attention mechanism load, (4) JSON constraints eliminating hallucination. The synergy between retrieval quality and prompt design suggests multiplicative rather than additive effects—better context requires better presentation for optimal synthesis.

\subsection{Limitations}

\textbf{LLM Choice:} Gemini 2.5 Flash, used due to budget constraints (free API tier vs.~\$500--\$1000 for GPT-4), likely underestimates SAPER's full potential. Wu et al.~\cite{wu2025rethinking} achieved higher absolute scores with GPT-4. However, our focus on \textit{relative} improvements under identical conditions remains valid. The largest gains on structure-dependent tasks with a mid-tier LLM suggest trends would amplify with stronger models.

\textbf{Sample Size:} Evaluation on 256/task (3 runs) provides statistical robustness for large effect sizes (+114\%) but may underrepresent rare protein families or edge cases. Full-dataset evaluation would enable stratified analysis by sequence length, structural complexity, and sequence identity to nearest training protein.

\textbf{Fixed Hyperparameters:} $\alpha=0.7$ optimizes average performance but is suboptimal per-task. Protein Function prefers $\alpha \approx 0.5$, Domain/Motif likely benefits from $\alpha > 0.7$. Task-specific or query-adaptive weighting could improve results.

\textbf{Prompt Design:} Enhanced prompts were manually designed for Gemini 2.5 Flash. Automated optimization (prompt tuning, LLM meta-prompting) could discover superior formulations and generalize across LLM families.

\textbf{Structural Embeddings:} ProstT5 relies on predicted structures (AlphaFold), propagating prediction errors. The discrete 3Di alphabet (20 states) discards fine-grained geometry like exact bond angles or long-range contacts. Alternative representations (3D coordinate GNNs, distance matrices) may capture richer information.

\subsection{Future Directions}

\textbf{State-of-the-Art LLMs:} Evaluate GPT-4 Turbo, Claude Opus 4.5, Llama 3.1 405B to assess whether relative improvements hold and absolute performance approaches expert levels. Model scaling analysis would quantify how SAPER benefits scale with LLM capability.

\textbf{Full Dataset:} Run on complete Prot-Inst-OOD test sets (thousands/task) for population-level estimates. Stratify by protein characteristics to identify where SAPER excels or struggles. Analyze confidence calibration—do retrieval scores correlate with accuracy?

\textbf{Adaptive Weighting:} Optimize $\alpha$ per-task via grid search, or develop instruction-based classifiers (keywords ``domain''/``motif'' $\rightarrow$ higher $\alpha$; ``pathway''/``process'' $\rightarrow$ lower $\alpha$). Query-adaptive weighting based on sequence identity to training set could further improve results.

\textbf{Multi-Modal Fusion:} Integrate AlphaFold 3D coordinates via GNNs, Gene Ontology semantic similarity, additional PLMs (ProtTrans, Ankh), and evolutionary features (MSA conservation, coevolution).

\textbf{Advanced Retrieval:} Learned similarity metrics (metric learning with GO supervision), cross-encoder re-ranking, graph-based retrieval (protein interaction networks), iterative refinement.

\textbf{Broader Applications:} Extend to protein-protein interaction prediction, mutation effect prediction (variant pathogenicity), drug-target binding, and de novo protein design.

\subsection{Conclusion}

SAPER demonstrates that incorporating structural information (ProstT5), optimizing multi-modal fusion (Weighted Similarity $\alpha=0.7$), and enhancing prompts substantially improves retrieval-augmented protein function prediction. Achieving +114\% improvement on Domain/Motif and +68.1\% average improvement validates the structure-function paradigm and shows structurally-aware retrieval bridges the gap between exponential sequence data growth and slower functional characterization.

Despite limitations (Gemini 2.5 Flash, 256-sample evaluation), directional consistency and mechanistic interpretability provide a foundation for future work. SAPER exemplifies a broader principle in AI for science: \textit{domain-aware design outperforms generic methods}. By encoding biological knowledge—structure-function relationships, sequence identity twilight zones, active site geometry importance—into retrieval and prompts, we achieve performance gains that purely data-driven approaches miss.
